{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APRENDIZAJE AUTOMÁTICO\n",
    "## MEMORIA Práctica 1: Auditoría de datos\n",
    "\n",
    "Miguel Ibáñez González  \n",
    "Alexandru Marius Platon  \n",
    "\n",
    "Grupo: 14  \n",
    "Fecha Entrega: 09/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obención de datos\n",
    "Cargamos el archivo comprimido en un DataFrame. Definimos una lista llamada columns que contiene los nombres de las columnas.  \n",
    "Usamos df.nunique() para calcular cuántos valores únicos existen en cada columna del DataFrame.  \n",
    "Contamos el numero de fraudes detectados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from os import path\n",
    "DATA_DIR = \".\"\n",
    "FILENAME = \"datos_practica.txt.gz\"\n",
    "FILEPATH = path.join(DATA_DIR, FILENAME)\n",
    "df = pd.read_csv(FILEPATH, sep='|', header=None)\n",
    "\n",
    "columns = [\n",
    "    \"Fecha Transaccion\", \"Hora Transaccion\", \"Cliente Id\", \"Perfil Cliente\", \"Segmento\", \"Ip\", \n",
    "    \"Modo Acceso\", \"Id Sesion\", \"Importe\", \"Tipo Mensaje\", \"Canal\", \"Fecha Sesion\", \"Hora Sesion\", \n",
    "    \"Medio Autenticacion\", \"Tipo Transaccion\", \"Entidad\", \"Oficina Origen\", \"Cuenta Origen\", \n",
    "    \"Entidad Destino\", \"Oficina Destino\", \"Cuenta Destino\", \"Tipo Firma\", \"Tipo Cuenta Origen\", \n",
    "    \"Pais Destino\", \"Fecha Alta Canal\", \"Fecha Activacion Canal\", \"Fecha Nac Titu Cta Cargo\", \n",
    "    \"Fecha Alta Cta Cargo\", \"Pais Ip\", \"Latitud\", \"Longitud\", \"Browser\", \"Browser Version\", \n",
    "    \"Os\", \"Os Version\", \"Profesion Cliente\", \"Sector Cliente\", \"Segmento Cliente\", \"Indicador Fraude\"\n",
    "]\n",
    "df.columns = columns\n",
    "unique_values_counts = df.nunique()\n",
    "fraude_count = (df[\"Indicador Fraude\"] == 1).sum()\n",
    "print(f\"Número de fraudes detectados:  {fraude_count}\")\n",
    "print(unique_values_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior vemos que pandas guarda los valores como enteros en la mayoría de los casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de Columnas\n",
    "Realizamos un filtrado básico de campos, eliminando aquellos que solo contienen un valor ya que no dan información adicional, y los campos que no ofrecen información de especial interés.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = unique_values_counts[unique_values_counts != 1].index\n",
    "filtered_df = df[filtered_columns]\n",
    "columns_to_drop = [\n",
    "    \"Cliente Id\", \"Ip\", \"Id Sesion\", \"Oficina Origen\", \"Cuenta Origen\", \n",
    "    \"Entidad Destino\", \"Oficina Destino\", \"Cuenta Destino\", \"Fecha Alta Canal\", \"Fecha Activacion Canal\", \n",
    "    \"Fecha Nac Titu Cta Cargo\", \"Fecha Alta Cta Cargo\", \"Latitud\", \"Longitud\",\n",
    "]\n",
    "\n",
    "filtered_df = filtered_df.drop(columns=columns_to_drop)\n",
    "print(filtered_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campos con un valor único\n",
    "- Segmento:  Vacio  \n",
    "- Browser:  Navegador desconocido  \n",
    "- Browser Version:  Vacio  \n",
    "- Os:  Os desconocido  \n",
    "- Os Version:  Vacio  \n",
    "- Profesion Cliente: Vacio  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Adicional: Frecuencia en campos categóricos con muchos valores\n",
    "Para las columnas descartadas, contamos los valores únicos y se imprimieron para dar contexto a su eliminación.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in columns_to_drop:\n",
    "    n_unicos = len(df[columna].dropna().unique())\n",
    "    print(f'Número de valores únicos en {columna}: {n_unicos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de datos númericos\n",
    "Creamos los histogramas y boxplots para visualizar la distribución de ciertos campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(filtered_df[\"Indicador Fraude\"], edgecolor='purple', color='pink')\n",
    "plt.title(f'Frecuencia de {\"Indicador Fraude\"}')\n",
    "unique_values = sorted(filtered_df[\"Indicador Fraude\"].unique())\n",
    "plt.xticks(unique_values, rotation=45)  \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "q75, q25 = np.percentile(filtered_df[\"Importe\"], [75, 25])\n",
    "iqr = q75 - q25 \n",
    "upper_limit = q75 + 1.5 * iqr\n",
    "filtered_data = filtered_df[filtered_df[\"Importe\"] <= upper_limit]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.boxplot(filtered_data[\"Importe\"], boxprops=dict(color='black'), \n",
    "            medianprops=dict(color='red'), whiskerprops=dict(color='black'), showmeans=True)\n",
    "\n",
    "plt.title('Boxplot de Importe')\n",
    "plt.xticks([1], ['Importe'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer gráfico, 1 indica que hay fraude mientras que 0 indica lo contrario. Dado que solo hay 82 fraudes mientras que hay casi 50.000 que no lo son, la barra de los fraudes casi no se aprecia.  \n",
    "\n",
    "En la segunda gráfica se muestra un boxplot dividido por percentiles donde se puede ver la mediana de los datos marcada por la línea roja. Se ve que generalmente las transacciones suelen ser de valores inferiores a 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de datos no númericos\n",
    "Eliminamos las columnas numéricas del DataFrame filtrado para enfocarse en los campos categóricos.  \n",
    "Creamos un gráfico de barras para las 40 categorías más frecuentes de cada campo categórico, visualizando su frecuencia.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numerical_fields = [\n",
    "  \"Indicador Fraude\", \"Fecha Transaccion\", \"Hora Transaccion\", \"Fecha Sesion\", \"Hora Sesion\", \"Importe\"\n",
    "]\n",
    "\n",
    "filtered_df = filtered_df.drop(columns=numerical_fields)\n",
    "\n",
    "filtered_df\n",
    "for field in filtered_df:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    #sns.histplot(x=df[field])\n",
    "    value_counts = filtered_df[field].value_counts().nlargest(40)\n",
    "    \n",
    "    plt.bar(value_counts.index, value_counts.values, edgecolor='purple', color='pink')\n",
    "    plt.title(f'Frecuencia de {field}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Campos de Fecha\n",
    "Convertimos \"Fecha Transacción\" y \"Fecha Sesión\" a formato de fecha y se generaron series temporales para visualizar la frecuencia de transacciones y sesiones a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Fecha Transaccion'] = pd.to_datetime(df['Fecha Transaccion'], format='%Y%m%d')\n",
    "df['Fecha Sesion'] = pd.to_datetime(df['Fecha Sesion'], format='%Y%m%d')\n",
    "date_fields = [\n",
    "    'Fecha Transaccion', 'Fecha Sesion',\n",
    "]\n",
    "\n",
    "for field in date_fields:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    time_series_data = df[field].value_counts().sort_index() \n",
    "    \n",
    "    plt.plot(time_series_data.index, time_series_data.values, marker='o', linestyle='-', color='black')\n",
    "    \n",
    "    plt.title(f'Serie Temporal de {field}')\n",
    "    plt.xlabel('Fechas')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    " \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las gráficas para Fecha Sesion y Fecha transacción son prácticamente idénticas.  \n",
    "Notamos también bajadas periódicas en el número de transacciones con frecuencia de una semana aproximadamente. Estas bajadas coinciden con fechas de fines de semana. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Campos de Hora\n",
    "Para el caso de las horas, tratamos los datos como cadenas de texto y seleccionamos solo los carácteres correspondientes a las horas (los dos primeros).   \n",
    "Posteriormente los mostramos como enteros para seguir un orden cronológico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_fields = [\n",
    "    \"Hora Transaccion\", \"Hora Sesion\"\n",
    "]\n",
    "\n",
    "df['Hora Transaccion'] = df['Hora Transaccion'].astype(str).str.zfill(6).str[:2].astype(int)\n",
    "df['Hora Sesion'] = df['Hora Sesion'].astype(str).str.zfill(6).str[:2].astype(int)\n",
    "\n",
    "for field in hour_fields:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(df[field], bins=23, edgecolor='purple', color='pink') \n",
    "    plt.title(f'Frecuencia de {field}')\n",
    "    plt.xlabel('Hora')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(range(24))  \n",
    "    plt.xlim(-0.5, 23.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede aprecias como entre las 00 y las 7 casi no hay transacciones (lo que es normal dado que es por la noche)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par de valores: Importe - Hora Transacción\n",
    "\n",
    "- Normalización: Utilizamos StandardScaler para normalizar las columnas de \"Importe\" para que tengan media 0 y desviación estándar 1. Esto permite que los datos se comparen en la misma escala. Al ser las horas un tipo de dato categórico, no es necesario normalizarlas.\n",
    "- Visualización: Usamos un gráfico de dispersión (scatter plot) para visualizar las transacciones genuinas (azul) y fraudulentas (rojo) según el importe y la hora, mostrando si hay algún patrón que distinga las operaciones fraudulentas de las genuinas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_df = df.copy()\n",
    "\n",
    "selected_fields = [\"Importe\", \"Hora Transaccion\", \"Indicador Fraude\"]\n",
    "selected_df = new_df[selected_fields]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "selected_df.loc[:, ['Importe']] = scaler.fit_transform(selected_df[['Importe']]).astype(int)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 0]['Importe'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 0]['Hora Transaccion'], \n",
    "            label=\"Genuino\", alpha=0.6, c=\"blue\", marker='o')\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 1]['Importe'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 1]['Hora Transaccion'], \n",
    "            label=\"Fraude\", alpha=0.6, c=\"red\", marker='x')\n",
    "\n",
    "plt.title(\"Importe vs. Hora de Transacción - Visualización en 2D (Normalizado)\")\n",
    "plt.xlabel(\"Importe Normalizado\")\n",
    "plt.ylabel(\"Hora de Transacción Normalizada\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los fraudes se producen a partir de las 08h hasta aproximadamente las 22h. Por otro lado, la gran mayoria de fraudes tienen valores cercanos a 0 como importes. En el gráfico de dispersión no se observan puntos claros en los que haya distinciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par de valores: Importe - Segmento Cliente\n",
    "\n",
    "- Normalización: Normalizamos el importe de la misma forma que en el apartado anterior. Segmento cliente es una campo categórico, por lo que no tendría mucho sentido normalizarlo.\n",
    "- Visualización: Creamos un gráfico de dispersión que muestra la relación entre \"Importe\" y \"Segmento Cliente\", diferenciando entre transacciones genuinas y fraudulentas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_df = df.copy()\n",
    "\n",
    "selected_fields = [\"Importe\", \"Segmento Cliente\", \"Indicador Fraude\"]\n",
    "selected_df = new_df[selected_fields]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "selected_df.loc[:, 'Importe'] = scaler.fit_transform(selected_df[['Importe']]).astype(int)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 0]['Importe'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 0]['Segmento Cliente'], \n",
    "            label=\"Genuino\", alpha=0.6, c=\"blue\", marker='o')\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 1]['Importe'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 1]['Segmento Cliente'], \n",
    "            label=\"Fraude\", alpha=0.6, c=\"red\", marker='x')\n",
    "\n",
    "plt.title(\"Importe vs. Segmento Cliente - Visualización en 2D (Normalizado)\")\n",
    "plt.xlabel(\"Importe Normalizado\")\n",
    "plt.ylabel(\"Segmento Cliente Codificado\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se puede distinguir algunos perfiles de clientes que son mas propensos a fraude que otros, entre el 31 y el 33 se producen prácticamente todos los fraudes. En este grafico de dispersión tampoco se observan puntos claros en los que haya distinciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par de valores: Tipo de Mensaje - Medio Autenticación\n",
    "- Normalización: En este caso se trata de dos campos categóricos, por lo que no se normalizan.  \n",
    "- Visualización: Creamos un gráfico de dispersión para comparar las transacciones genuinas y fraudulentas según el \"Tipo Mensaje\" y el \"Medio de Autenticación\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_df = df.copy()\n",
    "\n",
    "selected_fields = [\"Medio Autenticacion\", \"Tipo Mensaje\", \"Indicador Fraude\"]\n",
    "selected_df = new_df[selected_fields]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 0]['Tipo Mensaje'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 0]['Medio Autenticacion'], \n",
    "            label=\"Genuino\", alpha=0.6, c=\"blue\", marker='o')\t\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 1]['Tipo Mensaje'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 1]['Medio Autenticacion'], \n",
    "            label=\"Fraude\", alpha=0.6, c=\"red\", marker='x')\n",
    "\n",
    "plt.title(\"Tipo Mensaje vs. Medio Autenticacion - Visualización en 2D (Normalizado)\")\n",
    "plt.xlabel(\"Tipo Mensaje\")\n",
    "plt.ylabel(\"Medio Autenticacion\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este grafico se puede observar como todos los fraudes se producen con el Tipo de Mensaje PB, y como los con los Medios de Autenticación S2 y D3 no se producen fraudes. En este grafico de dispersión tampoco se observan puntos claros en los que haya distinciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par de valores: Tipo Firma - Medio Autenticación\n",
    "- Normalización: Se trata nuevamente de dos campos categóricos, por lo que no se aplica normalización.\n",
    "- Visualización: Creamos un scatter plot para ver la relación entre \"Tipo Firma\" y \"Medio Autenticación\" para transacciones genuinas y fraudulentas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "new_df = df.copy()\n",
    "\n",
    "\n",
    "selected_fields = [\"Medio Autenticacion\", \"Tipo Firma\", \"Indicador Fraude\"]\n",
    "selected_df = new_df[selected_fields]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 0]['Tipo Firma'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 0]['Medio Autenticacion'], \n",
    "            label=\"Genuino\", alpha=0.6, c=\"blue\", marker='o')\n",
    "plt.scatter(selected_df[selected_df['Indicador Fraude'] == 1]['Tipo Firma'], \n",
    "            selected_df[selected_df['Indicador Fraude'] == 1]['Medio Autenticacion'], \n",
    "            label=\"Fraude\", alpha=0.6, c=\"red\", marker='x')\n",
    "\n",
    "plt.title(\"Tipo Firma vs. Medio Autenticacion - Visualización en 2D (Normalizado)\")\n",
    "plt.xlabel(\"Tipo Firma\")\n",
    "plt.ylabel(\"Medio Autenticacion\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este grafico de dispersión se observa como las transacciones fraudulentas se realizan con los Tipos de Firma T3, T6, S1 y T1. En este grafico de dispersión tampoco se observan puntos claros en los que haya distinciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar todos estos pares de valores, vemos que no hay una clara distinción explicita entre las diferentes clases en función de los campos, pero sí observamos algunos campos que pueden indicar mayor probabilidad de fraude que otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos la probabilidad a priori de que una transacción sea fraudulenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "total_cases = len(new_df)\n",
    "fraud_cases = len(new_df[new_df['Indicador Fraude'] == 1])\n",
    "fraud_probability = fraud_cases / total_cases\n",
    "print(f'La probabilidad a priori de ser fraude es: {fraud_probability:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador DummyClassifier(strategy='stratified')\n",
    "\n",
    "- En `X` tomamos todos los valores menos la columna **\"Indicador Fraude\"**, que contiene la información de fraude y será la variable objetivo.\n",
    "- `y` es la variable objetivo, que contiene la columna **\"Indicador Fraude\"**.\n",
    "- `train_test_split()` divide los datos en conjuntos de entrenamiento (`X_train`, `y_train`) y de prueba (`X_test`, `y_test_stratified`).\n",
    "- Usamos el **20%** del total de los datos para la prueba (`test_size=0.2`), mientras que el **80%** se utiliza para el entrenamiento.\n",
    "- `random_state=42` garantiza que siempre se obtenga la misma división al ejecutar el código.\n",
    "- El clasificador hace predicciones respetando la proporción de clases en los datos.\n",
    "- Se entrena el modelo Dummy con los datos de entrenamiento (`X_train` y `y_train`).\n",
    "- `DummyClassifier` predice las etiquetas de fraude (`y_pred_stratified`) en los datos de prueba (`X_test`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = new_df.drop(columns=['Indicador Fraude'])\n",
    "y = new_df['Indicador Fraude']  \n",
    "\n",
    "X_train, X_test, y_train, y_test_stratified = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dummy_clf_stratified = DummyClassifier(strategy='stratified')\n",
    "\n",
    "dummy_clf_stratified.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stratified = dummy_clf_stratified.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador DummyClassifier(strategy='most_frequent')\n",
    "El clasificador usa la estrategia `'most_frequent'`, por lo que siempre predice la clase más frecuente en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score, recall_score\n",
    "\n",
    "\n",
    "X = new_df.drop(columns=['Indicador Fraude'])  \n",
    "y = new_df['Indicador Fraude'] \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test_most_frequent = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "dummy_clf_most_frequent = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "\n",
    "dummy_clf_most_frequent.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_most_frequent = dummy_clf_most_frequent.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular accuracy, sensitivity (TPR), specificity (TNR), balanced accuracy y la matriz de confusión para los dos casos\n",
    "- Matriz de Confusión: muestra los verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos para las predicciones del modelo.\n",
    "- Calculamos la matriz de confusión para los dos modelos (`cm_stratified` para el modelo estratificado y `cm_most_frequent` para el modelo de la clase más frecuente).\n",
    "- Con `accuracy_score()` medimos el porcentaje de predicciones correctas (cuántos ejemplos fueron bien clasificados).\n",
    "- Con `recall_score()` mostramos qué proporción de los fraudes reales fueron correctamente identificados por el modelo.\n",
    "- La **especificidad (TNR)** se calcula dividiendo los verdaderos negativos entre la suma de verdaderos negativos y falsos positivos. Esto indica qué proporción de las transacciones no fraudulentas fueron correctamente identificadas.\n",
    "- Con `balanced_accuracy_scoreo` medimos la precisión balanceada promedia, la sensibilidad (recall) y la especificidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "cm_stratified = confusion_matrix(y_test_stratified, y_pred_stratified)\n",
    "cm_most_frequent = confusion_matrix(y_test_most_frequent, y_pred_most_frequent)\n",
    "\n",
    "print(\"Métricas del Modelo Estratificado:\")\n",
    "print(f\"Precisión: {accuracy_score(y_test_stratified, y_pred_stratified):.4f}\")\n",
    "print(f\"Sensibilidad (TPR): {recall_score(y_test_stratified, y_pred_stratified):.4f}\")\n",
    "print(f\"Especificidad (TNR): {cm_stratified[0, 0] / (cm_stratified[0, 0] + cm_stratified[0, 1]):.4f}\")\n",
    "print(f\"Precisión Balanceada: {balanced_accuracy_score(y_test_stratified, y_pred_stratified):.4f}\")\n",
    "print(f\"Matriz de Confusión:\\n{cm_stratified}\\n\")\n",
    "\n",
    "print(\"Métricas del Modelo de Frecuencia Más Alta:\")\n",
    "print(f\"Precisión: {accuracy_score(y_test_most_frequent, y_pred_most_frequent):.4f}\")\n",
    "print(f\"Sensibilidad (TPR): {recall_score(y_test_most_frequent, y_pred_most_frequent):.4f}\")\n",
    "print(f\"Especificidad (TNR): {cm_most_frequent[0, 0] / (cm_most_frequent[0, 0] + cm_most_frequent[0, 1]):.4f}\")\n",
    "print(f\"Precisión Balanceada: {balanced_accuracy_score(y_test_most_frequent, y_pred_most_frequent):.4f}\")\n",
    "print(f\"Matriz de Confusión:\\n{cm_most_frequent}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "#### 1. Modelo Estratificado (`DummyClassifier(strategy='stratified')`)\n",
    "\n",
    "- **Precisión**: **0.9959**\n",
    "  - El modelo tiene una precisión del 99.59% (muy alta). Pero esto es porque la mayoría de las transacciones son **no fraudulentas**. Dado que el modelo no tiene poder predictivo, simplemente está replicando la proporción de clases en los datos.\n",
    "\n",
    "- **Sensibilidad (True Positive Rate - TPR)**: **0.0000**\n",
    "  - La sensibilidad es **0%**, lo que significa que el modelo **no identificó ningún fraude** correctamente. Este resultado tiene sentido, teniendo en cuenta la baja probabilidad de que una transacción sea fraudulenta y que el modelo solamente trata de igualar esa proporción de forma aleatoria.\n",
    "\n",
    "- **Especificidad (True Negative Rate - TNR)**: **0.9979**\n",
    "  - La especificidad es **muy alta (99.79%)**, indicando que el modelo es excelente para identificar transacciones **no fraudulentas**. Pero esto ocurre porque la mayoría de las transacciones pertenecen a esta clase de no fraudes.\n",
    "\n",
    "- **Precisión Balanceada**: **0.4990**\n",
    "  - La precisión balanceada es casi del 50%, lo que indica un rendimiento pobre en la clasificación de ambas clases (fraude y no fraude). Este valor destaca la diferencia entre la alta especificidad y la nula sensibilidad.\n",
    "\n",
    "- **Matriz de Confusión**: [9995 21] --> (No fraudes predichos como no fraudes, 9995 correctos y 21 incorrectos) [ 20 0]] --> (Fraudes predichos como fraudes, 0 correctos y 20 incorrectos)\n",
    "\n",
    "\n",
    "#### 2. Modelo de Frecuencia Más Alta (`DummyClassifier(strategy='most_frequent')`)\n",
    "\n",
    "- **Precisión**: **0.9980**\n",
    "- La precisión es aún mayor (99.80%) que en el modelo estratificado, pero, al igual que antes, esta alta precisión indica que el modelo predice la clase mayoritaria (no fraude) para la mayoría de los casos.\n",
    "\n",
    "- **Sensibilidad (TPR)**: **0.0000**\n",
    "- La sensibilidad es **0%**, lo que significa que este modelo también **no identifica ningún fraude**. Siempre predice la clase mayoritaria (no fraude), ignorando completamente los fraudes.\n",
    "\n",
    "- **Especificidad (TNR)**: **1.0000**\n",
    "- La especificidad es **100%**, lo que significa que el modelo clasifica todas las transacciones no fraudulentas de manera perfecta (no comete errores ya que sólo predice la clase no fraude).\n",
    "\n",
    "- **Precisión Balanceada**: **0.5000**\n",
    "- La precisión balanceada es **50%**, lo que refleja un desequilibrio completo: el modelo es perfecto en la clase no fraudulenta pero completamente ineficaz en la clase fraudulenta.\n",
    "\n",
    "- **Matriz de Confusión**: [[10016 0] --> (No fraudes predichos como no fraudes, 10016 correctos y 0 incorrectos) [ 20 0]] --> (Fraudes predichos como fraudes, 0 correctos y 20 incorrectos)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
